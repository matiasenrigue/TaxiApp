{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from tkinter.filedialog import asksaveasfilename\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the raw CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: c:\\diksha\\Summer Sem\\DataAnalysis\\Notebooks\\Cleaning\n",
      "Loaded file: C:/diksha/Summer Sem/DataAnalysis/Data/raw_data/Jan_Feb_Taxi.csv\n",
      "Initial shape: (5980729, 19)\n"
     ]
    }
   ],
   "source": [
    "# Verify your working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Select your raw CSV for taxi trip records\n",
    "Tk().withdraw()  # Hide the root window\n",
    "file_path = askopenfilename(title=\"Select your local taxi data CSV (ensure it's the raw data)\")\n",
    "original_filename = os.path.basename(file_path) \n",
    "\n",
    "# Check and load\n",
    "if not file_path or not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(\"File not found or not selected.\")\n",
    "else:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Loaded file:\", file_path)\n",
    "    print(\"Initial shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5980729 entries, 0 to 5980728\n",
      "Data columns (total 19 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   VendorID               int64  \n",
      " 1   tpep_pickup_datetime   object \n",
      " 2   tpep_dropoff_datetime  object \n",
      " 3   passenger_count        float64\n",
      " 4   trip_distance          float64\n",
      " 5   RatecodeID             float64\n",
      " 6   store_and_fwd_flag     object \n",
      " 7   PULocationID           int64  \n",
      " 8   DOLocationID           int64  \n",
      " 9   payment_type           int64  \n",
      " 10  fare_amount            float64\n",
      " 11  extra                  float64\n",
      " 12  mta_tax                float64\n",
      " 13  tip_amount             float64\n",
      " 14  tolls_amount           float64\n",
      " 15  improvement_surcharge  float64\n",
      " 16  total_amount           float64\n",
      " 17  congestion_surcharge   float64\n",
      " 18  airport_fee            float64\n",
      "dtypes: float64(12), int64(4), object(3)\n",
      "memory usage: 867.0+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nData Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
       "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
       "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
       "       'total_amount', 'congestion_surcharge', 'airport_fee'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>02/01/2023 12:00:00 AM</td>\n",
       "      <td>02/01/2023 12:15:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>16.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>02/01/2023 12:00:01 AM</td>\n",
       "      <td>02/01/2023 12:33:41 AM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>70.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>16.36</td>\n",
       "      <td>6.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.16</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>02/01/2023 12:00:02 AM</td>\n",
       "      <td>02/01/2023 12:11:08 AM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>186</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>12.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.36</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>02/01/2023 12:00:04 AM</td>\n",
       "      <td>02/01/2023 12:25:20 AM</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>90</td>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>29.60</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.60</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>02/01/2023 12:00:07 AM</td>\n",
       "      <td>02/01/2023 12:03:10 AM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>137</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>6.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID    tpep_pickup_datetime   tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  02/01/2023 12:00:00 AM  02/01/2023 12:15:00 AM              NaN   \n",
       "1         2  02/01/2023 12:00:01 AM  02/01/2023 12:33:41 AM              1.0   \n",
       "2         2  02/01/2023 12:00:02 AM  02/01/2023 12:11:08 AM              1.0   \n",
       "3         1  02/01/2023 12:00:04 AM  02/01/2023 12:25:20 AM              2.0   \n",
       "4         2  02/01/2023 12:00:07 AM  02/01/2023 12:03:10 AM              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           3.10         NaN                NaN           230            79   \n",
       "1          17.31         2.0                  N           132           170   \n",
       "2           1.91         1.0                  Y           186            48   \n",
       "3           6.40         1.0                  N            90           181   \n",
       "4           1.12         1.0                  N           137            79   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             0        16.83    0.0      0.5        4.17          0.00   \n",
       "1             1        70.00    0.0      0.5       16.36          6.55   \n",
       "2             1        12.80    1.0      0.5        3.56          0.00   \n",
       "3             1        29.60    3.5      0.5        3.00          0.00   \n",
       "4             1         6.50    1.0      0.5        2.30          0.00   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
       "0                    1.0         25.00                   NaN          NaN  \n",
       "1                    1.0         98.16                   2.5         1.25  \n",
       "2                    1.0         21.36                   2.5         0.00  \n",
       "3                    1.0         37.60                   2.5         0.00  \n",
       "4                    1.0         13.80                   2.5         0.00  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first few rows for the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardized Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime columns \n",
    "# Current Format '01/01/2023 12:00:00 AM'\n",
    "# New Format: '%m/%d/%Y %I:%M:%S %p'\n",
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'], format='%m/%d/%Y %I:%M:%S %p',errors='coerce')\n",
    "df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'], format='%m/%d/%Y %I:%M:%S %p',errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Localize timestamps to NYC timezone\n",
    "df['tpep_pickup_datetime'] = df['tpep_pickup_datetime'].dt.tz_localize(\n",
    "    'America/New_York',\n",
    "    ambiguous='NaT',\n",
    "    nonexistent='shift_forward'\n",
    ")\n",
    "\n",
    "df['tpep_dropoff_datetime'] = df['tpep_dropoff_datetime'].dt.tz_localize(\n",
    "    'America/New_York',\n",
    "    ambiguous='NaT',\n",
    "    nonexistent='shift_forward'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timezone info (pickup): America/New_York\n"
     ]
    }
   ],
   "source": [
    "# Confirm that timestamps are now timezone-aware\n",
    "print(\"Timezone info (pickup):\", df['tpep_pickup_datetime'].dt.tz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trip Duration Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute trip duration (in minutes)\n",
    "df['trip_duration_min'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaT or negative durations\n",
    "df = df[df['trip_duration_min'].notna()]\n",
    "df = df[df['trip_duration_min'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Type Conversion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric conversion\n",
    "num_cols = ['trip_distance', 'fare_amount', 'tip_amount', 'total_amount']\n",
    "df[num_cols] = df[num_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Categorical conversion\n",
    "cat_cols = ['RatecodeID', 'payment_type', 'VendorID']\n",
    "df[cat_cols] = df[cat_cols].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter Out Invalid/Extreme Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['trip_distance'] > 0) & (df['trip_distance'] < 100)] # Trip distance - Min: 0 miles, Max: 100 miles\n",
    "df = df[df['fare_amount'] > 0] # Tripe fare amount must be greater than 0\n",
    "df = df[df['trip_duration_min'] < 240]  # Trip duration is under 4 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Date and Time Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add pickup date and time features \n",
    "df['pickup_date'] = df['tpep_pickup_datetime'].dt.date\n",
    "df['pickup_hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "df['pickup_day_of_week'] = df['tpep_pickup_datetime'].dt.dayofweek  # 0 = Monday\n",
    "\n",
    "# add pickup date and time features \n",
    "df['droppoff_date'] = df['tpep_pickup_datetime'].dt.date\n",
    "df['pickup_hour'] = df['tpep_pickup_datetime'].dt.hour\n",
    "df['pickup_day_of_week'] = df['tpep_pickup_datetime'].dt.dayofweek  # 0 = Monday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Pickup and Dropoff Location IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after location ID filtering: (5741476, 24)\n"
     ]
    }
   ],
   "source": [
    "# Filter invalid PULocationID and DOLocationID\n",
    "initial_rows = df.shape[0]\n",
    "initial_rows\n",
    "df = df[(df['PULocationID'].between(1, 263)) & (df['DOLocationID'].between(1, 263))]\n",
    "print(f\"Shape after location ID filtering: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Taxi Zone Lookup File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tk().withdraw()  # Hide the root window\n",
    "zone_file_path = askopenfilename(title=\"Select the taxi zone lookup CSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded zone lookup file: C:/diksha/Summer Sem/DataAnalysis/Data/raw_data/taxi_zone_lookup.csv\n",
      "Zone file shape: (265, 4)\n"
     ]
    }
   ],
   "source": [
    "# Check and load\n",
    "if not zone_file_path or not os.path.exists(zone_file_path):\n",
    "    raise FileNotFoundError(\"Zone lookup file not found or not selected.\")\n",
    "else:\n",
    "    zones = pd.read_csv(zone_file_path, keep_default_na=True, delimiter=',', skipinitialspace=True)\n",
    "    zone_lookup = zones.copy()\n",
    "    print(\"Loaded zone lookup file:\", zone_file_path)\n",
    "    print(\"Zone file shape:\", zones.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge pickup location info\n",
    "df = df.merge(\n",
    "    zone_lookup.rename(columns={\n",
    "        \"LocationID\": \"PULocationID\",\n",
    "        \"Zone\": \"pickup_zone\",\n",
    "        \"Borough\": \"pickup_borough\",\n",
    "        \"service_zone\": \"pickup_service_zone\"\n",
    "    }),\n",
    "    on=\"PULocationID\", how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dropoff location info\n",
    "df = df.merge(\n",
    "    zone_lookup.rename(columns={\n",
    "        \"LocationID\": \"DOLocationID\",\n",
    "        \"Zone\": \"dropoff_zone\",\n",
    "        \"Borough\": \"dropoff_borough\",\n",
    "        \"service_zone\": \"dropoff_service_zone\"\n",
    "    }),\n",
    "    on=\"DOLocationID\", how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'VendorID', 'RatecodeID', 'store_and_fwd_flag', 'passenger_count',\n",
    "    'payment_type', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount',\n",
    "    'improvement_surcharge', 'congestion_surcharge', 'airport_fee',\n",
    "    'total_amount',  # derived field\n",
    "    'PULocationID', 'DOLocationID'  # drop since we now have zone/borough\n",
    "]\n",
    "df = df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Additional Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derived feature for fare per minute (target variable)\n",
    "df['fare_per_minute'] = df['fare_amount'] / df['trip_duration_min']\n",
    "# Filter out extreme fare per minute values\n",
    "# This removes any fare_per_minute that is zero or above the 99th percentile\n",
    "df = df[(df['fare_per_minute'] > 0) & (df['fare_per_minute'] < df['fare_per_minute'].quantile(0.99))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anar2\\AppData\\Local\\Temp\\ipykernel_21180\\2589620814.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['fare_per_mile'].replace([np.inf, -np.inf], np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Derived feature for fare per mile (feature important for distance-based pricing)\n",
    "# Compute fare per mile\n",
    "df['fare_per_mile'] = df['fare_amount'] / df['trip_distance']\n",
    "df.loc[:, 'fare_per_mile'] = df['fare_per_mile'].replace([np.inf, -np.inf], np.nan)\n",
    "df = df[df['fare_per_mile'].notna()]\n",
    "\n",
    "# Filter out extreme fare_per_mile values\n",
    "df['fare_per_mile'] = df['fare_per_mile'].replace([np.inf, -np.inf], np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derived feature for trip speed\n",
    "df['trip_speed'] = df['trip_distance'] / df['trip_duration_min']  # miles per minute\n",
    "df['trip_speed_mph'] = df['trip_speed'] * 60\n",
    "df = df[(df['trip_speed_mph'] > 1) & (df['trip_speed_mph'] < 60)] # reasonable speed limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deriving feature for time of day based on segmenting\n",
    "def time_of_day(hour):\n",
    "    if 0 <= hour < 5:\n",
    "        return 'Early Morning'\n",
    "    elif 5 <= hour < 10:\n",
    "        return 'Morning Rush'\n",
    "    elif 10 <= hour < 15:\n",
    "        return 'Midday'\n",
    "    elif 15 <= hour < 19:\n",
    "        return 'Evening Rush'\n",
    "    else:\n",
    "        return 'Night'\n",
    "df['time_of_day'] = df['pickup_hour'].apply(time_of_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create weekday/weekend label\n",
    "df['day_type'] = df['pickup_day_of_week'].apply(lambda x: 'Weekend' if x >= 5 else 'Weekday')\n",
    "#Add Day Type (Weekday vs Weekend) weekend flag\n",
    "df['is_weekend'] = df['pickup_day_of_week'].isin([5, 6])  # Saturday = 5, Sunday = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define known airport zones \n",
    "airport_keywords = [\n",
    "    'JFK', 'John F Kennedy', 'Kennedy',\n",
    "    'LGA', 'LaGuardia',\n",
    "    'EWR', 'Newark'\n",
    "]\n",
    "\n",
    "# Convert to string and check for substring match\n",
    "df['is_airport_pickup'] = df['pickup_zone'].astype(str).str.contains('|'.join(airport_keywords), case=False, na=False)\n",
    "df['is_airport_dropoff'] = df['dropoff_zone'].astype(str).str.contains('|'.join(airport_keywords), case=False, na=False)\n",
    "\n",
    "# Flag for any trip involving an airport\n",
    "df['is_airport_trip'] = df['is_airport_pickup'] | df['is_airport_dropoff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total airport trips: 537943\n",
      "Pickup at airport only: 427744\n",
      "Dropoff at airport only: 121129\n"
     ]
    }
   ],
   "source": [
    "print(\"Total airport trips:\", df['is_airport_trip'].sum())\n",
    "print(\"Pickup at airport only:\", df['is_airport_pickup'].sum())\n",
    "print(\"Dropoff at airport only:\", df['is_airport_dropoff'].sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Clean DF to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5.681617e+06\n",
       "mean     1.798191e+01\n",
       "std      1.523653e+01\n",
       "min      1.000000e-02\n",
       "25%      9.300000e+00\n",
       "50%      1.280000e+01\n",
       "75%      1.980000e+01\n",
       "max      5.133000e+02\n",
       "Name: fare_amount, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fare_amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5681617 entries, 0 to 5741475\n",
      "Data columns (total 25 columns):\n",
      " #   Column                 Dtype                           \n",
      "---  ------                 -----                           \n",
      " 0   tpep_pickup_datetime   datetime64[ns, America/New_York]\n",
      " 1   tpep_dropoff_datetime  datetime64[ns, America/New_York]\n",
      " 2   trip_distance          float64                         \n",
      " 3   fare_amount            float64                         \n",
      " 4   trip_duration_min      float64                         \n",
      " 5   pickup_date            object                          \n",
      " 6   pickup_hour            int32                           \n",
      " 7   pickup_day_of_week     int32                           \n",
      " 8   droppoff_date          object                          \n",
      " 9   pickup_borough         object                          \n",
      " 10  pickup_zone            object                          \n",
      " 11  pickup_service_zone    object                          \n",
      " 12  dropoff_borough        object                          \n",
      " 13  dropoff_zone           object                          \n",
      " 14  dropoff_service_zone   object                          \n",
      " 15  fare_per_minute        float64                         \n",
      " 16  fare_per_mile          float64                         \n",
      " 17  trip_speed             float64                         \n",
      " 18  trip_speed_mph         float64                         \n",
      " 19  time_of_day            object                          \n",
      " 20  day_type               object                          \n",
      " 21  is_weekend             bool                            \n",
      " 22  is_airport_pickup      bool                            \n",
      " 23  is_airport_dropoff     bool                            \n",
      " 24  is_airport_trip        bool                            \n",
      "dtypes: bool(4), datetime64[ns, America/New_York](2), float64(7), int32(2), object(10)\n",
      "memory usage: 932.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Data Types Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['pickup_borough', 'pickup_zone', 'pickup_service_zone',\n",
    "            'dropoff_borough', 'dropoff_zone', 'dropoff_service_zone',\n",
    "            'time_of_day', 'day_type', ]\n",
    "\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pickup_date'] = pd.to_datetime(df['pickup_date'])\n",
    "df['droppoff_date'] = pd.to_datetime(df['droppoff_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enforce Consistant Data Types (used for scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data types standardized. Ready for export or modeling.\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = [\n",
    "    'trip_distance', 'fare_amount', 'trip_duration_min',\n",
    "    'fare_per_minute', 'trip_speed', 'trip_speed_mph'\n",
    "]\n",
    "\n",
    "int_cols = ['pickup_hour', 'pickup_day_of_week']\n",
    "bool_cols = ['is_weekend']\n",
    "\n",
    "# Convert numeric fields to float\n",
    "for col in numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').astype(float)\n",
    "\n",
    "# Convert integer fields to int\n",
    "for col in int_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').astype(int)\n",
    "\n",
    "# Ensure boolean field is properly typed\n",
    "df['is_weekend'] = df['is_weekend'].astype(bool)\n",
    "\n",
    "\n",
    "print(\" Data types standardized. Ready for export or modeling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5681617, 25)\n",
      "5681617\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)  # Final row count should be > 0\n",
    "print(df['tpep_pickup_datetime'].notna().sum())  # Should match row count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Cleaned Dataframe to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved to: C:/diksha/Summer Sem/DataAnalysis/Data/cleaned/Clean_Jan_Feb_Taxi.csv\n",
      "Final shape: (5681617, 25)\n"
     ]
    }
   ],
   "source": [
    "default_filename = \"Clean_\" + original_filename\n",
    "\n",
    "# Hide the root Tkinter window\n",
    "Tk().withdraw()\n",
    "\n",
    "# Open save file dialog (no default path logic)\n",
    "save_path = asksaveasfilename(\n",
    "    initialfile=default_filename,\n",
    "    title=\"Select where to save cleaned taxi data CSV\",\n",
    "    defaultextension=\".csv\",\n",
    "    filetypes=[(\"CSV files\", \"*.csv\")]\n",
    ")\n",
    "\n",
    "if save_path:\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"Cleaned dataset saved to: {save_path}\")\n",
    "    print(f\"Final shape: {df.shape}\")\n",
    "else:\n",
    "    print(\"Save cancelled, file was not saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
