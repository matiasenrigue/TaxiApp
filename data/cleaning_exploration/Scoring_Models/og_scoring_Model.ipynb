{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91aab630",
   "metadata": {},
   "source": [
    "## Inital Scoring Model \n",
    "\n",
    "This is the first model I will make that will combine xgboost and lightgbm to get the feature importance to show that the features that we picked are actually important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71790ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from tkinter.filedialog import asksaveasfilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6464f9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clean file with all features enginnered for jan-feb\n",
    "Tk().withdraw()\n",
    "file_path = askopenfilename(title=\"Select Jan–Feb Cleaned with Features CSV\")\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"Loaded:\", file_path)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab0a0aa",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2fca665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: C:/diksha/Summer Sem/DataAnalysis/Data/Full Scoring Model/jan_feb_all_features.csv\n",
      "Shape: (5609910, 32)\n",
      "Time-based Scoring Model Evaluation (Train: Jan, Test: Feb):\n",
      "R² Score: 0.4243\n",
      "MAE: 0.1752\n",
      "\n",
      "Top Features:\n",
      "dropoff_borough_EWR          0.257927\n",
      "fare_per_mile                0.204493\n",
      "is_airport_trip              0.094014\n",
      "trip_duration_variability    0.072462\n",
      "time_of_day_Evening Rush     0.070376\n",
      "dropoff_borough_Brooklyn     0.068495\n",
      "time_of_day_Night            0.042064\n",
      "time_of_day_Midday           0.034612\n",
      "pickup_borough_Queens        0.032801\n",
      "dropoff_borough_Manhattan    0.029399\n",
      "dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# Load file\n",
    "Tk().withdraw()\n",
    "file_path = askopenfilename(title=\"Select Cleaned CSV with Hotspot Score\")\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Loaded:\", file_path)\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "# Step 1: Set your target and features\n",
    "target_col = 'fare_per_minute'\n",
    "categorical_cols = ['pickup_borough', 'dropoff_borough', 'time_of_day', 'is_airport_trip']\n",
    "numeric_cols = ['fare_per_mile', 'dropoff_zone_hotness', 'trip_duration_variability', 'hotspot_score']\n",
    "feature_cols = categorical_cols + numeric_cols\n",
    "\n",
    "# Step 2: Ensure date column is parsed and clean\n",
    "df['pickup_date'] = pd.to_datetime(df['pickup_date'])\n",
    "df = df.dropna(subset=[target_col])  # Drop rows with missing target\n",
    "\n",
    "# Step 3: Time-based split (Jan → train, Feb → test)\n",
    "train_df = df[df['pickup_date'].dt.month == 1].copy()\n",
    "test_df = df[df['pickup_date'].dt.month == 2].copy()\n",
    "\n",
    "# Step 4: Preprocess features\n",
    "X_train_cat = pd.get_dummies(train_df[categorical_cols], drop_first=True)\n",
    "X_test_cat = pd.get_dummies(test_df[categorical_cols], drop_first=True)\n",
    "\n",
    "# Align test set columns to training set\n",
    "X_test_cat = X_test_cat.reindex(columns=X_train_cat.columns, fill_value=0)\n",
    "\n",
    "X_train = pd.concat([train_df[numeric_cols].reset_index(drop=True), X_train_cat.reset_index(drop=True)], axis=1)\n",
    "X_test = pd.concat([test_df[numeric_cols].reset_index(drop=True), X_test_cat.reset_index(drop=True)], axis=1)\n",
    "\n",
    "y_train = train_df[target_col]\n",
    "y_test = test_df[target_col]\n",
    "\n",
    "# Step 5: Train model\n",
    "model = XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "feature_importance = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "# Step 7: Output results\n",
    "print(f\"Time-based Scoring Model Evaluation (Train: Jan, Test: Feb):\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(\"\\nTop Features:\")\n",
    "print(feature_importance.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0ef3d1",
   "metadata": {},
   "source": [
    "## LIGHTGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "617dc3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: C:/diksha/Summer Sem/DataAnalysis/Data/Full Scoring Model/jan_feb_all_features.csv\n",
      "Shape: (5609910, 32)\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073063 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 793\n",
      "[LightGBM] [Info] Number of data points in the train set: 2871008, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 1.262351\n",
      "LightGBM Time-Based Model (Train: Jan, Test: Feb):\n",
      "R² Score: 0.4091\n",
      "MAE: 0.1776\n",
      "\n",
      "Top Features:\n",
      "fare_per_mile                1244\n",
      "trip_duration_variability     555\n",
      "dropoff_zone_hotness          388\n",
      "time_of_day_Evening Rush      111\n",
      "is_airport_trip               101\n",
      "time_of_day_Midday             86\n",
      "time_of_day_Night              79\n",
      "pickup_borough_Queens          73\n",
      "dropoff_borough_Manhattan      70\n",
      "time_of_day_Morning Rush       69\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Load file\n",
    "Tk().withdraw()\n",
    "file_path = askopenfilename(title=\"Select Cleaned CSV with Hotspot Score\")\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Loaded:\", file_path)\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "# Step 1: Set target and features\n",
    "target_col = 'fare_per_minute'\n",
    "categorical_cols = ['pickup_borough', 'dropoff_borough', 'time_of_day', 'is_airport_trip']\n",
    "numeric_cols = ['fare_per_mile', 'dropoff_zone_hotness', 'trip_duration_variability', 'hotspot_score']\n",
    "feature_cols = categorical_cols + numeric_cols\n",
    "\n",
    "# Step 2: Parse pickup_date\n",
    "df['pickup_date'] = pd.to_datetime(df['pickup_date'])\n",
    "df = df.dropna(subset=[target_col])\n",
    "\n",
    "# Step 3: Time-based split\n",
    "train_df = df[df['pickup_date'].dt.month == 1].copy()\n",
    "test_df = df[df['pickup_date'].dt.month == 2].copy()\n",
    "\n",
    "# Step 4: Encode categorical features\n",
    "X_train_cat = pd.get_dummies(train_df[categorical_cols], drop_first=True)\n",
    "X_test_cat = pd.get_dummies(test_df[categorical_cols], drop_first=True)\n",
    "X_test_cat = X_test_cat.reindex(columns=X_train_cat.columns, fill_value=0)\n",
    "\n",
    "# Combine with numeric\n",
    "X_train = pd.concat([train_df[numeric_cols].reset_index(drop=True), X_train_cat.reset_index(drop=True)], axis=1)\n",
    "X_test = pd.concat([test_df[numeric_cols].reset_index(drop=True), X_test_cat.reset_index(drop=True)], axis=1)\n",
    "\n",
    "y_train = train_df[target_col]\n",
    "y_test = test_df[target_col]\n",
    "\n",
    "# Step 5: Train LightGBM\n",
    "model = LGBMRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "feature_importance = pd.Series(model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "# Step 7: Output results\n",
    "print(f\"LightGBM Time-Based Model (Train: Jan, Test: Feb):\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(\"\\nTop Features:\")\n",
    "print(feature_importance.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
